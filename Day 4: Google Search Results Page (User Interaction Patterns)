Question 1 of 3
Identify and remove any duplicate entries in the dataset to ensure data quality. How many duplicates were found and removed?

import pandas as pd

# Check initial number of rows
initial_count = len(df)

# Remove duplicates
df = df.drop_duplicates()

# Check final number of rows
final_count = len(df)

# Calculate how many were removed
duplicates_removed = initial_count - final_count

print(f"‚úÖ Number of duplicate rows removed: {duplicates_removed}")


Question 2 of 3
I want to group the cleaned data by the number of search results displayed and then calculate the average interaction time for each group.

(assumming df is already cleaned)

import pandas as pd

# Group by number of search results displayed and calculate average interaction time
avg_interaction = df.groupby('search_results_displayed')['interaction_time'].mean().reset_index()

# Rename the column for clarity
avg_interaction.columns = ['search_results_displayed', 'average_interaction_time']

print(avg_interaction)


Question 3 of 3
Think about how you can sort your aggregated results from Question 2 to find the highest average interaction time. The number of search results with the highest average interaction time will be your answer.

import pandas as pd

# From question 2
df.columns = df.columns.str.strip()
df = df.drop_duplicates()
df['interaction_time'] = pd.to_numeric(df['interaction_time'], errors='coerce')
df = df.dropna(subset=['interaction_time', 'search_results_displayed'])
avg_interaction = df.groupby('search_results_displayed')['interaction_time'].mean().reset_index()
avg_interaction.columns = ['search_results_displayed', 'average_interaction_time']

# Find the number of search results with the highest average interaction time
max_row = avg_interaction.sort_values(by='average_interaction_time', ascending=False).head(1)

print("üîç Number of search results with the highest average interaction time:")
print(max_row)
